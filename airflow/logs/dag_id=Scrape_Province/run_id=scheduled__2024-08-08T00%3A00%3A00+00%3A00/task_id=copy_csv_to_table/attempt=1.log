[2024-08-09T08:56:01.419+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-09T08:56:01.436+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [queued]>
[2024-08-09T08:56:01.446+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [queued]>
[2024-08-09T08:56:01.447+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-08-09T08:56:01.633+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): copy_csv_to_table> on 2024-08-08 00:00:00+00:00
[2024-08-09T08:56:01.644+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1107) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-08-09T08:56:01.646+0000] {standard_task_runner.py:63} INFO - Started process 1109 to run task
[2024-08-09T08:56:01.647+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Scrape_Province', 'copy_csv_to_table', 'scheduled__2024-08-08T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/Province_Extraction.py', '--cfg-path', '/tmp/tmpty4xgj9w']
[2024-08-09T08:56:01.649+0000] {standard_task_runner.py:91} INFO - Job 61: Subtask copy_csv_to_table
[2024-08-09T08:56:01.664+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2024-08-09T08:56:01.702+0000] {task_command.py:426} INFO - Running <TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [running]> on host ubuntu
[2024-08-09T08:56:01.792+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Ducky' AIRFLOW_CTX_DAG_ID='Scrape_Province' AIRFLOW_CTX_TASK_ID='copy_csv_to_table' AIRFLOW_CTX_EXECUTION_DATE='2024-08-08T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-08T00:00:00+00:00'
[2024-08-09T08:56:01.794+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-09T08:56:01.828+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn_raw' for task execution.
[2024-08-09T08:56:01.829+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.36
[2024-08-09T08:56:01.830+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-08-09T08:56:02.580+0000] {logging_mixin.py:188} INFO - Connected to Snowflake Successfully!
[2024-08-09T08:56:02.610+0000] {logging_mixin.py:188} INFO - s3://s3-poc-data-marketplace/Province/province_table-20240808.csv
[2024-08-09T08:56:02.610+0000] {logging_mixin.py:188} INFO - 
        COPY INTO RAW_PROVINCE
        FROM 's3://s3-poc-data-marketplace/Province/province_table-20240808.csv'
        CREDENTIALS = (AWS_KEY_ID='AKIA5FTZBUCGQ4SERYPG' AWS_SECRET_KEY='***')
        FILE_FORMAT = (TYPE = 'CSV', FIELD_OPTIONALLY_ENCLOSED_BY = '"', DATE_FORMAT = 'YYYYMMDD', SKIP_HEADER = 1);
        
[2024-08-09T08:56:04.005+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-08-09T08:56:04.005+0000] {connection.py:762} INFO - closed
[2024-08-09T08:56:04.117+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-08-09T08:56:04.258+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-08-09T08:56:04.259+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-09T08:56:04.271+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Scrape_Province, task_id=copy_csv_to_table, run_id=scheduled__2024-08-08T00:00:00+00:00, execution_date=20240808T000000, start_date=20240809T085601, end_date=20240809T085604
[2024-08-09T08:56:04.311+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-09T08:56:04.336+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-09T08:56:04.338+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-08-09T09:01:29.507+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-09T09:01:29.709+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [queued]>
[2024-08-09T09:01:29.719+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [queued]>
[2024-08-09T09:01:29.719+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-08-09T09:01:29.733+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): copy_csv_to_table> on 2024-08-08 00:00:00+00:00
[2024-08-09T09:01:29.745+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1252) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-08-09T09:01:29.746+0000] {standard_task_runner.py:63} INFO - Started process 1254 to run task
[2024-08-09T09:01:29.748+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'Scrape_Province', 'copy_csv_to_table', 'scheduled__2024-08-08T00:00:00+00:00', '--job-id', '76', '--raw', '--subdir', 'DAGS_FOLDER/Province_Extraction.py', '--cfg-path', '/tmp/tmp6p8vf713']
[2024-08-09T09:01:29.751+0000] {standard_task_runner.py:91} INFO - Job 76: Subtask copy_csv_to_table
[2024-08-09T09:01:29.766+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2024-08-09T09:01:29.804+0000] {task_command.py:426} INFO - Running <TaskInstance: Scrape_Province.copy_csv_to_table scheduled__2024-08-08T00:00:00+00:00 [running]> on host ubuntu
[2024-08-09T09:01:29.897+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Ducky' AIRFLOW_CTX_DAG_ID='Scrape_Province' AIRFLOW_CTX_TASK_ID='copy_csv_to_table' AIRFLOW_CTX_EXECUTION_DATE='2024-08-08T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-08T00:00:00+00:00'
[2024-08-09T09:01:29.899+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-09T09:01:29.929+0000] {base.py:84} INFO - Using connection ID 'snowflake_conn_raw' for task execution.
[2024-08-09T09:01:29.930+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-6.8.0-1009-aws-x86_64-with-glibc2.36
[2024-08-09T09:01:29.931+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-08-09T09:01:30.629+0000] {logging_mixin.py:188} INFO - Connected to Snowflake Successfully!
[2024-08-09T09:01:30.655+0000] {logging_mixin.py:188} INFO - s3://s3-poc-data-marketplace/Province/province_table-20240808.csv
[2024-08-09T09:01:30.655+0000] {logging_mixin.py:188} INFO - 
        COPY INTO RAW_PROVINCE
        FROM 's3://s3-poc-data-marketplace/Province/province_table-20240808.csv'
        CREDENTIALS = (AWS_KEY_ID='AKIA5FTZBUCGQ4SERYPG' AWS_SECRET_KEY='***')
        FILE_FORMAT = (TYPE = 'CSV', FIELD_OPTIONALLY_ENCLOSED_BY = '"', DATE_FORMAT = 'YYYYMMDD', SKIP_HEADER = 1);
        
[2024-08-09T09:01:32.928+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-08-09T09:01:32.929+0000] {connection.py:762} INFO - closed
[2024-08-09T09:01:33.040+0000] {connection.py:768} INFO - No async queries seem to be running, deleting session
[2024-08-09T09:01:33.168+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-08-09T09:01:33.169+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-09T09:01:33.179+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=Scrape_Province, task_id=copy_csv_to_table, run_id=scheduled__2024-08-08T00:00:00+00:00, execution_date=20240808T000000, start_date=20240809T090129, end_date=20240809T090133
[2024-08-09T09:01:33.217+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-08-09T09:01:33.248+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-08-09T09:01:33.252+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
